{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5c34c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Class Mapping Script Starting...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print(\"Text to Class Mapping Script Starting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c1d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 classes: ['COMPANY', 'ADDRESS', 'DATE', 'TOTAL', 'TAX', 'ITEM', 'QTY', 'UNIT_PRICE', 'LINE_TOTAL', 'DOCUMENT_NO', 'CASHIER', 'OTHER']\n"
     ]
    }
   ],
   "source": [
    "# Define final classes\n",
    "CLASSES = [\n",
    "    \"COMPANY\",\n",
    "    \"ADDRESS\", \n",
    "    \"DATE\",\n",
    "    \"TOTAL\",\n",
    "    \"TAX\",\n",
    "    \"ITEM\",\n",
    "    \"QTY\",\n",
    "    \"UNIT_PRICE\",\n",
    "    \"LINE_TOTAL\",\n",
    "    \"DOCUMENT_NO\",\n",
    "    \"CASHIER\",\n",
    "    \"OTHER\"\n",
    "]\n",
    "\n",
    "print(f\"Using {len(CLASSES)} classes: {CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da822f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_class(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply deterministic mapping rules to assign class to text.\n",
    "    \n",
    "    Args:\n",
    "        text: OCR text to classify\n",
    "        \n",
    "    Returns:\n",
    "        Class name from CLASSES list\n",
    "    \"\"\"\n",
    "    text_lower = text.lower().strip()\n",
    "    text_clean = re.sub(r'[^\\w\\s.,/:-]', '', text_lower)\n",
    "    \n",
    "    # DATE patterns\n",
    "    date_patterns = [\n",
    "        r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b',  # MM/DD/YYYY or DD/MM/YYYY\n",
    "        r'\\b\\d{2,4}[/-]\\d{1,2}[/-]\\d{1,2}\\b',  # YYYY/MM/DD\n",
    "        r'\\b\\d{1,2}\\s+(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\\s+\\d{2,4}\\b',  # DD MMM YYYY\n",
    "        r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\s+\\d{1,2},?\\s+\\d{2,4}\\b'\n",
    "    ]\n",
    "    \n",
    "    for pattern in date_patterns:\n",
    "        if re.search(pattern, text_clean):\n",
    "            return \"DATE\"\n",
    "    \n",
    "    # TOTAL patterns (price regex + total keywords)\n",
    "    total_keywords = ['total', 'grand total', 'amount due', 'net amount', 'final amount', 'sum', 'balance']\n",
    "    price_pattern = r'\\b\\d{1,6}[.,]\\d{2}\\b|\\$\\s*\\d+[.,]?\\d*|rs\\.?\\s*\\d+'\n",
    "    \n",
    "    has_price = re.search(price_pattern, text_clean)\n",
    "    has_total_keyword = any(keyword in text_clean for keyword in total_keywords)\n",
    "    \n",
    "    if has_price and has_total_keyword:\n",
    "        return \"TOTAL\"\n",
    "    \n",
    "    # TAX patterns\n",
    "    tax_keywords = ['tax', 'vat', 'gst', 'service tax', 'sales tax', 'cgst', 'sgst', 'igst']\n",
    "    if any(keyword in text_clean for keyword in tax_keywords):\n",
    "        return \"TAX\"\n",
    "    \n",
    "    # QTY patterns\n",
    "    qty_patterns = [\n",
    "        r'\\b\\d+\\s*(pc|pcs|piece|pieces|qty|quantity|nos|units?)\\b',\n",
    "        r'\\b(qty|quantity)\\s*:?\\s*\\d+\\b',\n",
    "        r'^\\d+$',  # Just a number by itself\n",
    "    ]\n",
    "    \n",
    "    for pattern in qty_patterns:\n",
    "        if re.search(pattern, text_clean) and len(text_clean) < 15:  # Short quantity strings\n",
    "            return \"QTY\"\n",
    "    \n",
    "    # UNIT_PRICE and LINE_TOTAL (price-like numbers with currency)\n",
    "    currency_price_patterns = [\n",
    "        r'\\$\\s*\\d+[.,]\\d{2}\\b',\n",
    "        r'rs\\.?\\s*\\d+[.,]?\\d*\\b',\n",
    "        r'\\b\\d{1,4}[.,]\\d{2}\\s*$'  # Clean price at end\n",
    "    ]\n",
    "    \n",
    "    for pattern in currency_price_patterns:\n",
    "        if re.search(pattern, text_clean):\n",
    "            # Distinguish between unit price and line total based on context\n",
    "            if any(word in text_clean for word in ['each', 'per', 'rate', 'unit']):\n",
    "                return \"UNIT_PRICE\"\n",
    "            else:\n",
    "                return \"LINE_TOTAL\"\n",
    "    \n",
    "    # COMPANY patterns\n",
    "    company_indicators = ['ltd', 'inc', 'corp', 'company', 'co.', 'pvt', 'llc', 'llp', 'limited']\n",
    "    if any(indicator in text_clean for indicator in company_indicators):\n",
    "        return \"COMPANY\"\n",
    "    \n",
    "    # ADDRESS patterns\n",
    "    address_keywords = ['street', 'road', 'avenue', 'lane', 'drive', 'city', 'state', 'zip', 'pin', 'area', 'nagar', 'colony']\n",
    "    address_patterns = [\n",
    "        r'\\b\\d+\\s+[a-zA-Z]+\\s+(street|st|road|rd|avenue|ave|lane|drive|dr)\\b',\n",
    "        r'\\b\\d{5,6}\\b'  # PIN/ZIP codes\n",
    "    ]\n",
    "    \n",
    "    has_address_keyword = any(keyword in text_clean for keyword in address_keywords)\n",
    "    has_address_pattern = any(re.search(pattern, text_clean) for pattern in address_patterns)\n",
    "    \n",
    "    if has_address_keyword or has_address_pattern:\n",
    "        return \"ADDRESS\"\n",
    "    \n",
    "    # DOCUMENT_NO patterns\n",
    "    doc_keywords = ['invoice', 'receipt', 'bill no', 'order no', 'ref no', 'document', 'ticket']\n",
    "    doc_patterns = [\n",
    "        r'\\b[a-zA-Z]{1,3}\\d{4,}\\b',  # Pattern like INV1234, RCP5678\n",
    "        r'\\b\\d{6,}\\b'  # Long number sequences\n",
    "    ]\n",
    "    \n",
    "    has_doc_keyword = any(keyword in text_clean for keyword in doc_keywords)\n",
    "    has_doc_pattern = any(re.search(pattern, text_clean) for pattern in doc_patterns)\n",
    "    \n",
    "    if has_doc_keyword or has_doc_pattern:\n",
    "        return \"DOCUMENT_NO\"\n",
    "    \n",
    "    # CASHIER patterns\n",
    "    if 'cashier' in text_clean or 'served by' in text_clean:\n",
    "        return \"CASHIER\"\n",
    "    \n",
    "    # ITEM patterns (alpha-heavy with some digits, product names)\n",
    "    # Items are typically longer text with mixed alphanumeric\n",
    "    alpha_count = sum(1 for c in text_clean if c.isalpha())\n",
    "    digit_count = sum(1 for c in text_clean if c.isdigit())\n",
    "    total_chars = len(re.sub(r'\\s+', '', text_clean))\n",
    "    \n",
    "    if (total_chars > 5 and alpha_count > digit_count and \n",
    "        alpha_count / total_chars > 0.6 and\n",
    "        not has_price and not has_total_keyword and\n",
    "        len(text_clean) > 3):\n",
    "        return \"ITEM\"\n",
    "    \n",
    "    # Fallback\n",
    "    return \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eda89c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing classification function:\n",
      "'ABC Company Ltd' → COMPANY\n",
      "'12/03/2023' → DATE\n",
      "'Total: $45.99' → TOTAL\n",
      "'GST 18%' → TAX\n",
      "'2 PCS' → QTY\n",
      "'Rate: $15.00' → UNIT_PRICE\n",
      "'Coffee Latte Medium' → ITEM\n",
      "'123 Main Street' → ADDRESS\n",
      "'INV123456' → DOCUMENT_NO\n",
      "'Cashier: John' → CASHIER\n",
      "'Random text here' → ITEM\n"
     ]
    }
   ],
   "source": [
    "# Test the classification function with some examples\n",
    "test_texts = [\n",
    "    \"ABC Company Ltd\",\n",
    "    \"12/03/2023\",\n",
    "    \"Total: $45.99\",\n",
    "    \"GST 18%\",\n",
    "    \"2 PCS\",\n",
    "    \"Rate: $15.00\",\n",
    "    \"Coffee Latte Medium\",\n",
    "    \"123 Main Street\",\n",
    "    \"INV123456\",\n",
    "    \"Cashier: John\",\n",
    "    \"Random text here\"\n",
    "]\n",
    "\n",
    "print(\"Testing classification function:\")\n",
    "for text in test_texts:\n",
    "    predicted_class = assign_class(text)\n",
    "    print(f\"'{text}' → {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd58bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files from: ../../dataset/intermediate\n",
      "Output directory: ../../dataset/labels_raw\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "intermediate_dir = \"../../dataset/intermediate\"\n",
    "output_dir = \"../../dataset/labels_raw\"\n",
    "\n",
    "# Create output directory\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Processing files from: {intermediate_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40801763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 626 intermediate files to process\n",
      "Processed 50 files...\n",
      "Processed 100 files...\n",
      "Processed 150 files...\n",
      "Processed 200 files...\n",
      "Processed 250 files...\n",
      "Processed 300 files...\n",
      "Processed 350 files...\n",
      "Processed 400 files...\n",
      "Processed 450 files...\n",
      "Processed 500 files...\n",
      "Processed 550 files...\n",
      "Processed 600 files...\n"
     ]
    }
   ],
   "source": [
    "# Process all intermediate bbox files\n",
    "intermediate_files = list(Path(intermediate_dir).glob(\"*_bboxes.json\"))\n",
    "\n",
    "print(f\"Found {len(intermediate_files)} intermediate files to process\")\n",
    "\n",
    "processed_count = 0\n",
    "total_bboxes = 0\n",
    "class_counts = {cls: 0 for cls in CLASSES}\n",
    "\n",
    "for bbox_file in intermediate_files:\n",
    "    stem = bbox_file.stem.replace('_bboxes', '')  # Remove _bboxes suffix\n",
    "    output_file = Path(output_dir) / f\"{stem}.json\"\n",
    "    \n",
    "    try:\n",
    "        # Load intermediate bbox data\n",
    "        with open(bbox_file, 'r', encoding='utf-8') as f:\n",
    "            bbox_items = json.load(f)\n",
    "        \n",
    "        labeled_items = []\n",
    "        \n",
    "        # Assign classes to each bbox\n",
    "        for item in bbox_items:\n",
    "            text = item['text']\n",
    "            assigned_class = assign_class(text)\n",
    "            class_id = CLASSES.index(assigned_class)\n",
    "            \n",
    "            labeled_item = {\n",
    "                \"bbox\": item['bbox'],\n",
    "                \"text\": text,\n",
    "                \"class\": assigned_class,\n",
    "                \"class_id\": class_id\n",
    "            }\n",
    "            \n",
    "            labeled_items.append(labeled_item)\n",
    "            class_counts[assigned_class] += 1\n",
    "            total_bboxes += 1\n",
    "        \n",
    "        # Save labeled data\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(labeled_items, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        processed_count += 1\n",
    "        \n",
    "        if processed_count % 50 == 0:\n",
    "            print(f\"Processed {processed_count} files...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {bbox_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d82d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEXT TO CLASS MAPPING SUMMARY\n",
      "==================================================\n",
      "Processed files: 626\n",
      "Total bounding boxes: 33626\n",
      "Average bboxes per file: 53.7\n",
      "\n",
      "Class Distribution:\n",
      "   0. COMPANY     :    161 (  0.5%)\n",
      "   1. ADDRESS     :   1315 (  3.9%)\n",
      "   2. DATE        :    763 (  2.3%)\n",
      "   3. TOTAL       :     88 (  0.3%)\n",
      "   4. TAX         :   3555 ( 10.6%)\n",
      "   5. ITEM        :   8206 ( 24.4%)\n",
      "   6. QTY         :   2875 (  8.5%)\n",
      "   7. UNIT_PRICE  :      1 (  0.0%)\n",
      "   8. LINE_TOTAL  :   7004 ( 20.8%)\n",
      "   9. DOCUMENT_NO :   1511 (  4.5%)\n",
      "  10. CASHIER     :    282 (  0.8%)\n",
      "  11. OTHER       :   7865 ( 23.4%)\n",
      "\n",
      "Output files saved to: ../../dataset/labels_raw\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sample classifications from X00016469612.json:\n",
      "  1. 'TAN WOON YANN...' → ITEM\n",
      "  2. 'BOOK TA .K(TAMAN DAYA) SDN BND...' → ITEM\n",
      "  3. '789417-W...' → ADDRESS\n",
      "  4. 'NO.53 55,57 & 59, JALAN SAGU 18,...' → OTHER\n",
      "  5. 'TAMAN DAYA,...' → ITEM\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEXT TO CLASS MAPPING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Processed files: {processed_count}\")\n",
    "print(f\"Total bounding boxes: {total_bboxes}\")\n",
    "print(f\"Average bboxes per file: {total_bboxes/processed_count:.1f}\" if processed_count > 0 else \"\")\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "for i, cls in enumerate(CLASSES):\n",
    "    count = class_counts[cls]\n",
    "    percentage = (count / total_bboxes * 100) if total_bboxes > 0 else 0\n",
    "    print(f\"  {i:2d}. {cls:12s}: {count:6d} ({percentage:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nOutput files saved to: {output_dir}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Show sample classifications\n",
    "sample_files = list(Path(output_dir).glob(\"*.json\"))[:2]\n",
    "if sample_files:\n",
    "    print(f\"\\nSample classifications from {sample_files[0].name}:\")\n",
    "    with open(sample_files[0], 'r', encoding='utf-8') as f:\n",
    "        sample_data = json.load(f)\n",
    "        for i, item in enumerate(sample_data[:5]):\n",
    "            print(f\"  {i+1}. '{item['text'][:40]}...' → {item['class']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
