{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f00ffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Split Creation Script Starting...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "print(\"Train/Val Split Creation Script Starting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0695ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images(images_dir: str, seed: int = 42, val_ratio: float = 0.1) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Split image files into train and validation sets.\n",
    "    \n",
    "    Args:\n",
    "        images_dir: Directory containing image files\n",
    "        seed: Random seed for reproducible splits\n",
    "        val_ratio: Fraction of data to use for validation\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_files, val_files)\n",
    "    \"\"\"\n",
    "    # Get all image files\n",
    "    image_dir = Path(images_dir)\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n",
    "    \n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(image_dir.glob(f\"*{ext}\"))\n",
    "    \n",
    "    # Convert to relative paths (images/filename.jpg)\n",
    "    image_paths = [f\"images/{img.name}\" for img in image_files]\n",
    "    \n",
    "    # Shuffle deterministically\n",
    "    random.seed(seed)\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    # Split into train/val\n",
    "    total_count = len(image_paths)\n",
    "    val_count = int(total_count * val_ratio)\n",
    "    train_count = total_count - val_count\n",
    "    \n",
    "    val_files = image_paths[:val_count]\n",
    "    train_files = image_paths[val_count:]\n",
    "    \n",
    "    print(f\"Total images: {total_count}\")\n",
    "    print(f\"Training images: {train_count} ({(train_count/total_count)*100:.1f}%)\")\n",
    "    print(f\"Validation images: {val_count} ({(val_count/total_count)*100:.1f}%)\")\n",
    "    \n",
    "    return train_files, val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a024c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images directory: ../../dataset/images\n",
      "Validation ratio: 10.0%\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "images_dir = \"../../dataset/images\"\n",
    "train_file = \"../../dataset/train.txt\"\n",
    "val_file = \"../../dataset/val.txt\"\n",
    "data_yaml_file = \"../../dataset/data.yaml\"\n",
    "\n",
    "# Configuration\n",
    "SEED = 42\n",
    "VAL_RATIO = 0.1  # 10% for validation\n",
    "\n",
    "print(f\"Images directory: {images_dir}\")\n",
    "print(f\"Validation ratio: {VAL_RATIO*100:.1f}%\")\n",
    "print(f\"Random seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22db28ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found images directory: ../../dataset/images\n"
     ]
    }
   ],
   "source": [
    "# Check if images directory exists\n",
    "if not Path(images_dir).exists():\n",
    "    print(f\"Error: Images directory {images_dir} does not exist!\")\n",
    "    print(\"Please run the previous notebook (5_write_yolo_labels.ipynb) first.\")\n",
    "else:\n",
    "    print(f\"Found images directory: {images_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715c90c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation split...\n",
      "Total images: 1252\n",
      "Training images: 1127 (90.0%)\n",
      "Validation images: 125 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Create train/val split\n",
    "print(\"Creating train/validation split...\")\n",
    "train_images, val_images = split_images(images_dir, seed=SEED, val_ratio=VAL_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1957b932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train file: ../../dataset/train.txt (1127 images)\n"
     ]
    }
   ],
   "source": [
    "# Write train.txt file\n",
    "with open(train_file, 'w', encoding='utf-8') as f:\n",
    "    for img_path in train_images:\n",
    "        f.write(f\"{img_path}\\n\")\n",
    "\n",
    "print(f\"Created train file: {train_file} ({len(train_images)} images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d590ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created validation file: ../../dataset/val.txt (125 images)\n"
     ]
    }
   ],
   "source": [
    "# Write val.txt file\n",
    "with open(val_file, 'w', encoding='utf-8') as f:\n",
    "    for img_path in val_images:\n",
    "        f.write(f\"{img_path}\\n\")\n",
    "\n",
    "print(f\"Created validation file: {val_file} ({len(val_images)} images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d756c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data.yaml file: ../../dataset/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Update data.yaml file to point to split files\n",
    "if Path(data_yaml_file).exists():\n",
    "    # Load existing data.yaml\n",
    "    with open(data_yaml_file, 'r', encoding='utf-8') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    # Update train and val paths\n",
    "    data_config['train'] = 'train.txt'\n",
    "    data_config['val'] = 'val.txt'\n",
    "    \n",
    "    # Save updated data.yaml\n",
    "    with open(data_yaml_file, 'w', encoding='utf-8') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False, allow_unicode=True)\n",
    "    \n",
    "    print(f\"Updated data.yaml file: {data_yaml_file}\")\n",
    "else:\n",
    "    print(f\"Warning: {data_yaml_file} not found. Please run notebook 5 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee0dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying label files exist for all images...\n",
      "✓ All sample images have corresponding label files\n"
     ]
    }
   ],
   "source": [
    "# Verify that corresponding label files exist\n",
    "labels_dir = \"../../dataset/labels\"\n",
    "missing_labels = []\n",
    "\n",
    "print(\"\\nVerifying label files exist for all images...\")\n",
    "\n",
    "all_images = train_images + val_images\n",
    "for img_path in all_images[:10]:  # Check first 10 as sample\n",
    "    # Convert images/filename.jpg to labels/filename.txt\n",
    "    img_name = Path(img_path).stem  # Get filename without extension\n",
    "    label_file = Path(labels_dir) / f\"{img_name}.txt\"\n",
    "    \n",
    "    if not label_file.exists():\n",
    "        missing_labels.append(img_path)\n",
    "\n",
    "if missing_labels:\n",
    "    print(f\"Warning: {len(missing_labels)} images have no corresponding label files\")\n",
    "    print(f\"Sample missing: {missing_labels[:5]}\")\n",
    "else:\n",
    "    print(\"✓ All sample images have corresponding label files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca61bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAIN/VAL SPLIT SUMMARY\n",
      "==================================================\n",
      "Total images: 1252\n",
      "Training images: 1127 (90.0%)\n",
      "Validation images: 125 (10.0%)\n",
      "Random seed: 42\n",
      "\n",
      "Files created:\n",
      "  Train split: ../../dataset/train.txt\n",
      "  Val split: ../../dataset/val.txt\n",
      "  Updated config: ../../dataset/data.yaml\n",
      "\n",
      "Sample train images:\n",
      "  1. images/X51007846412.jpg\n",
      "  2. images/X51005711447.jpg\n",
      "  3. images/X51008114266.jpg\n",
      "  4. images/X51005433514.jpg\n",
      "  5. images/X51007103692.jpg\n",
      "\n",
      "Sample validation images:\n",
      "  1. images/X51006311780.jpg\n",
      "  2. images/X51005433494.jpg\n",
      "  3. images/X51006311758.jpg\n",
      "  4. images/X51006619343.jpg\n",
      "  5. images/X51005724629.jpg\n",
      "\n",
      "==================================================\n",
      "Ready for YOLO training!\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAIN/VAL SPLIT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total images: {len(train_images) + len(val_images)}\")\n",
    "print(f\"Training images: {len(train_images)} ({len(train_images)/(len(train_images)+len(val_images))*100:.1f}%)\")\n",
    "print(f\"Validation images: {len(val_images)} ({len(val_images)/(len(train_images)+len(val_images))*100:.1f}%)\")\n",
    "print(f\"Random seed: {SEED}\")\n",
    "\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  Train split: {train_file}\")\n",
    "print(f\"  Val split: {val_file}\")\n",
    "print(f\"  Updated config: {data_yaml_file}\")\n",
    "\n",
    "print(\"\\nSample train images:\")\n",
    "for i, img in enumerate(train_images[:5]):\n",
    "    print(f\"  {i+1}. {img}\")\n",
    "\n",
    "print(\"\\nSample validation images:\")\n",
    "for i, img in enumerate(val_images[:5]):\n",
    "    print(f\"  {i+1}. {img}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ready for YOLO training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533a91e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final ../../dataset/data.yaml content:\n",
      "names:\n",
      "- COMPANY\n",
      "- ADDRESS\n",
      "- DATE\n",
      "- TOTAL\n",
      "- TAX\n",
      "- ITEM\n",
      "- QTY\n",
      "- UNIT_PRICE\n",
      "- LINE_TOTAL\n",
      "- DOCUMENT_NO\n",
      "- CASHIER\n",
      "- OTHER\n",
      "nc: 12\n",
      "path: dataset\n",
      "train: train.txt\n",
      "val: val.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show final data.yaml content\n",
    "if Path(data_yaml_file).exists():\n",
    "    print(f\"\\nFinal {data_yaml_file} content:\")\n",
    "    with open(data_yaml_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
